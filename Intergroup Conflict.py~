
# coding: utf-8

# In[17]:

"""
This is a model to explore the effect of the intergroup conflict escalation on the collective behavior of individuals' 
opinion dynamics.
The model coded here is a modified version of the bounded confidence with rejection mechanism model that was originally proposed 
by Huet et al (2008).
Please note that for values of m=1 and beta=1, the proposed model equals to Huet et al (2008).

Meysam Alizadeh
Department of Computational Social Science
George Mason University
March 2014
malizad2@gmu.edu
"""

# Importing necessary libraries
import random
import numpy as np
import matplotlib.pyplot as plt
import networkx as nx
import scipy as sp
from scipy import stats


# In[39]:

"""
Defining constant variables
"""
mu = 0.3 # constriction factor used to limit the convergence velocity
delta = 1 # intolerance threshold
beta = 3 # conflict escalation intolerance coefficient
no_of_runs = 1 # Number of times the whole model will be run 
max_iter = 1000000 # maximum number of iteration at each run
no_of_agents = 1000
U = 0.2 # level of uncertainty
epsilon = 0.15 # minimum distance between agents to consider them in a same cluster
m = 5 # number of initial groupings
p = 0.1 # connectivity probability of the random network


# In[3]:

"""
Defining the psign function.
"""
def psign (x):
    if x >= 0:
        x = 1
    else:
        x = -1
    return x


# In[4]:

"""
Initialization of the Model.
We represent each person as an agent in our model.
Each agent has a following attributes:
    1) Opinion: a list containing 2 real random number between -1 and 1 
    2) Uncertainty (U): a list containing 2 real random number between 0 and 1 (here U is always set as 0.2)
"""
    
# Defining the init method: a special method that gets invoked when an object is instantiated
def init():
    global op1, op2, grouping, network, adj_mat
    op1 = [(-1 + 2 * random.random()) for agents in range(no_of_agents)]
    op2 = [(-1 + 2 * random.random()) for agents in range(no_of_agents)]
    grouping = [random.randint(1,m) for agents in range(no_of_agents)]
    network = nx.erdos_renyi_graph(no_of_agents,p)
    adj_mat = nx.adjacency_matrix(network)


# In[10]:

"""
Updating Rules
"""

def Interact():
    global op1, op2, grouping, network, adj_mat

    # Selecting two random agents among all agents that are immediate neighbor on the network
    
    while True:
        node1 = random.randint(0, no_of_agents - 1)
        node2 = random.randint(0, no_of_agents - 1)
        if (node1 != node2) and (adj_mat[node1,node2] == 1):
            break
        
    # Calculating new opinion based on opinion interaction rules

    op1_diff = abs (op1[node2] - op1[node1])
    op2_diff = abs (op2[node2] - op2[node1])
        
    if grouping[node1] == grouping[node2]: # check whether the two selected agents are from same group
            
        if op1_diff <= U and op2_diff <= U:
            op1[node1] = op1[node1] + mu * (op1[node2] - op1[node1])
            op2[node1] = op2[node1] + mu * (op2[node2] - op2[node1])
            op1[node2] = op1[node2] + mu * (op1[node1] - op1[node2])
            op2[node2] = op2[node2] + mu * (op2[node1] - op2[node2])
    
        elif op1_diff > U and op2_diff <= U and op1_diff <= (1 + delta) * U:
            op2[node1] = op2[node1] + mu * (op2[node2] - op2[node1])       
            op2[node2] = op2[node2] + mu * (op2[node1] - op2[node2]) 
                
        elif op1_diff <= U and op2_diff > U and op2_diff <= (1 + delta) * U:       
            op1[node1] = op1[node1] + mu * (op1[node2] - op1[node1])
            op1[node2] = op1[node2] + mu * (op1[node1] - op1[node2])
                
        elif op1_diff > U and op2_diff <= U and op1_diff > (1 + delta) * U:
            op2[node1] = op2[node1] - mu * psign(op2[node2] - op2[node1]) * (U - op2_diff)
            op2[node2] = op2[node2] - mu * psign(op2[node1] - op2[node2]) * (U - op2_diff)            
    
        elif op1_diff <= U and op2_diff > U and op2_diff > (1 + delta) * U:
            op1[node1] = op1[node1] - mu * psign(op1[node2] - op1[node1]) * (U - op1_diff)
            op1[node2] = op1[node2] - mu * psign(op1[node1] - op1[node2]) * (U - op1_diff)
            
    else: # if agents are not from the same group
        
        if op1_diff <= U and op2_diff <= U:
            op1[node1] = op1[node1] + mu * (op1[node2] - op1[node1])
            op2[node1] = op2[node1] + mu * (op2[node2] - op2[node1])
            op1[node2] = op1[node2] + mu * (op1[node1] - op1[node2])
            op2[node2] = op2[node2] + mu * (op2[node1] - op2[node2])
                
        elif op1_diff > U and op2_diff <= U and op1_diff > (1 + delta) * U:
            op2[node1] = op2[node1] - beta * mu * psign(op2[node2] - op2[node1]) * (U - op2_diff)
            op2[node2] = op2[node2] - beta * mu * psign(op2[node1] - op2[node2]) * (U - op2_diff)            
    
        elif op1_diff <= U and op2_diff > U and op2_diff > (1 + delta) * U:
            op1[node1] = op1[node1] - beta * mu * psign(op1[node2] - op1[node1]) * (U - op1_diff)
            op1[node2] = op1[node2] - beta * mu * psign(op1[node1] - op1[node2]) * (U - op1_diff)
        
# bounding the opinions between -1 and 1
    #if abs(op1[node1]) > 1: op1[node1] = psign(op1[node1])
    #if abs(op1[node2]) > 1: op1[node2] = psign(op1[node2])
    #if abs(op2[node1]) > 1: op2[node1] = psign(op2[node1])
    #if abs(op2[node2]) > 1: op2[node2] = psign(op2[node2])


# In[6]:

"""
Compute Number of Clusters in the Final Opinion Distribution
The algortihm is adopted from Deffuant (2006) and Huet et al (2008)
"""
def CompNoClusters():
    cluster_array = np.zeros((100,500))
    clusters = 0
    for i in range(no_of_agents):
        while True:
            a = cluster_array[np.where(cluster_array == i)]
            if a.size > 0:
                break
            else:
                clusters += 1
                current_cluster = []
                current_cluster.append(i)
                for j in range(no_of_agents):
                    delta1 = op1[i] - op1[j]
                    delta2 = op2[i] - op2[j]
                    if sqrt((delta1**2) + (delta2**2)) < epsilon:
                        current_cluster.append(j)
                for x in range (len(current_cluster)):   
                    cluster_array[clusters - 1][x] = current_cluster[x]
                
    cluster_size_list = list()
    for m in range(50):
        if cluster_array[m][0] == 0:
            break
        else:
            cluster_size = 0
            for n in range (300):
                if cluster_array[m][n] > 0:
                    cluster_size += 1
            cluster_size_list.append(cluster_size)
            if cluster_size < 0.01*no_of_agents:
                clusters -= 1
    print 'Number of Clusters = ', clusters


# In[7]:

"""
Compute Number of Extremists
"""
def CompNoExtremists():
    extreme1 = 0
    extreme2 = 0
    for opinion1 in range(len(op1)):
        if abs(op1[opinion1]) >= 0.9:
            extreme1 += 1
    for opinion2 in range(len(op2)):
        if abs(op2[opinion2]) >= 0.9:
            extreme2 += 1
    NoExtremists = extreme1 + extreme2
    print 'Number of Extremists = ', NoExtremists


# In[40]:

"""
Main
"""

init()    
for j in range(max_iter):
    Interact()   
        
plt.plot(op1, op2, 'ro')
plt.title('Final Configuration of Opinions')
plt.xlabel('Opinion 1')
plt.ylabel('Opinion 2')
plt.show() 
#CompNoClusters()
#CompNoExtremists()


# In[41]:

hist(op1)


# In[42]:

pos_op1=list()
for g in range(len(op1)):
    if op1[g]>= 0:
        pos_op1.append(op1[g])


# In[44]:

nl, ns = stats.norm.fit(op1)
x=np.linspace(-4,4,100)
pdf_fitted = stats.norm.pdf(x, nl, ns)
plot(x,pdf_fitted,'g-',label='Normal')
hist(op1,normed=1,alpha=0.3)
xlabel('Opinion1')
ylabel('Normalized Frequency')
legend(loc='upper right')


# In[45]:

abs_op1=list()
abs_op2=list()
for i in range(len(op1)):
    abs_op1.append(abs(op1[i]))
for i in range(len(op2)):
    abs_op2.append(abs(op2[i]))


# In[47]:

lnsh, lnl, lns = stats.lognorm.fit(abs_op1,loc=0)
exl, exs = stats.expon.fit(abs_op1,loc=0)
x=np.linspace(0,3.5,100)
ln_pdf_fitted = stats.lognorm.pdf(x, lnsh, loc=lnl, scale=lns) # fitted distribution
ex_pdf_fitted = stats.expon.pdf(x, loc=0, scale=exs)
plot(x,ln_pdf_fitted,'g-',label='Lognormal')
plot(x,ex_pdf_fitted,'r--',label='Exponential')
hist(abs_op1,bins=10,normed=True,alpha=0.3)
legend(loc='upper right')
xlabel('Opinion 1')
ylabel('Normalized Frequency')


# In[48]:

freq = histogram(abs_op1,bins=20)[0]
tem = histogram(abs_op1,bins=20)[1]
vals=list()
# Calculating complementery cumulative density function P(X>x) in search fot type IV power law 
cfreq = list()
for i in range(len(freq)):
    temp = 0
    for j in range(i,len(freq)):
        temp += freq[j]
    cfreq.append(temp)
for k in range(len(tem)-1):
    vals.append(tem[k])
plot(log(vals),log(cfreq),'ro')
xlabel('log(Opinion1)')
ylabel('log(P(X>x))')


# In[49]:

"""
Comparing upper tail of sample against some distributions
"""
# 1. Exponential
l, s = stats.expon.fit(abs_op1)
crit = stats.expon(l,s).ppf([0.5, 0.7, 0.9, 0.95, 0.99])
frq = list()
p=[0.5,0.3,0.1,0.05,0.01]
for i in range(5):
    frq.append(np.sum(abs_op1>crit[i]) / float(len(op1)))
plot(crit,frq,label='Empirical')
plot(crit,p,'g--',label='Exponential')
xlabel('Critical Values')
ylabel('P(x >= Critical Value)')
legend(loc='upper right')


# In[57]:

# 2. Lognormal
sh, l, s = stats.powerlaw.fit(abs_op1)
crit = stats.powerlaw(sh,l,s).ppf([0.5, 0.7, 0.9, 0.95, 0.99])
frq = list()
p=[0.5,0.3,0.1,0.05,0.01]
for i in range(5):
    frq.append(np.sum(abs_op1>crit[i]) / float(len(op1)))
plot(crit,frq,label='Empirical')
plot(crit,p,'g--',label='Lognormal')
xlabel('Critical Values')
ylabel('P(x >= Critical Value)')
legend(loc='upper right')

